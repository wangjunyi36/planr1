univeral_config: &univeral_config
  mode: "plan"
  token_dict_path: tokens/tokens_1024.pt
  num_tokens: 1024
  interval: 5
  num_historical_steps: 20
  num_future_steps: 80

datamodule:
  <<: *univeral_config
  # root: 原始 nuPlan 数据根目录，需包含 nuplan-v1.1/splits/train
  root: /mnt/nuplan
  save_dir: /root/wangjunyi/data/planr1
  dir: mini
  train_batch_size: 4
  val_batch_size: 4
  shuffle: True
  num_workers: 8
  pin_memory: True
  persistent_workers: True
  num_samples_per_second: 10
  num_total_scenarios: 100000
  ratio: 0.1
  parallel: True

trainer:
  ckpt_path: ckpts/pre-training.ckpt
  strategy: ddp_find_unused_parameters_true
  accelerator: "gpu"
  devices: 1
  max_epochs: 5
  # 每多少个 step 打印一次训练日志，小于每 epoch 的 batch 数才能看到 step 日志
  log_every_n_steps: 10
  ckpt:
    monitor: val_reward
    save_top_k: 5
    mode: max
  lr_monitor:
    logging_interval: epoch
  csv_logger:
    save_dir: lightning_logs
    name: plan
  tensorboard_logger:
    save_dir: lightning_logs
    name: plan

model:
  <<: *univeral_config
  hidden_dim: 128
  num_heads: 8
  num_attn_layers: 6
  num_hops: 4
  agent_radius: 60
  polygon_radius: 30
  pred_top_k: 1
  plan_top_k: 1
  rollout_top_k: 50
  num_samples: 4
  beta: 0.1
  scaling_factor: 0.1
  dropout: 0.1
  lr: 0.000004
  weight_decay: 0.0001
  warmup_epochs: 0
  T_max: 32
  val_visualization: True
  val_visualization_interval: 10
  comfort_reward_weight: 2
  ttc_reward_weight: 5
  speed_limit_reward_weight: 2
  progress_reward_weight: 1
